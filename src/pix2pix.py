import pytorch_lightning as pl
import torch
import torch.optim as o
import torch.nn as nn
import torch.nn.functional as func
import numpy as np
import matplotlib.pyplot as plt

from torchmetrics.functional import peak_signal_noise_ratio, accuracy, structural_similarity_index_measure
from torchmetrics.functional.image import relative_average_spectral_error, spectral_angle_mapper

import config as c
import src.utils as u
from src.models.unet_model import Generator as Unet
from src.models.unet2d_model import Generator as Unet2D
from src.models.fp_unet_model import Generator as FP_Unet
from src.models.simple_fp_unet_model import Generator as Simple_FP_Unet
from src.models.outside_fp_unet_model import Generator as Outside_FP_Unet
from src.models.discriminator_model import Discriminator

class Pix2Pix(pl.LightningModule):
    def __init__(self, run):
        super(Pix2Pix, self).__init__()
        # self.save_hyperparameters()
        # Important to disable automatic optimization as it 
        # will be done manually as there are two optimizators
        self.automatic_optimization = False
        self.generator_lr = c.LEARNING_RATE               # Generator learning rate
        self.discriminator_lr = c.LEARNING_RATE       # Discriminator learning rate

        # Models
        self.discriminator = Discriminator(in_channels_x=c.SHAPE_X[0], in_channels_y=c.SHAPE_Y[0]).to(c.DEVICE)
        match c.GENERATOR_MODEL:
            case "unet":
                self.generator = Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "unet2d":
                self.generator = Unet2D(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "fp_unet":
                self.generator = FP_Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "simple_fp_unet":
                self.generator = Simple_FP_Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "outside_fp_unet":
                self.generator = Outside_FP_Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case _:
                print(f"Generator model {c.GENERATOR_MODEL} not defined.")

        # Loss Functions
        # (now using "functional" to minimize gpu memory)
        self.BCE = nn.BCEWithLogitsLoss()
        # self.L1_LOSS = nn.L1Loss()
        # self.SPECTRAL_LOSS = SpectralAngleMapper()
        # self.RASE_LOSS = RelativeAverageSpectralError()
        # self.SSIM_LOSS = StructuralSimilarityIndexMeasure()

        self.val_outputs = np.array([])
        self.last_epoch_logged = -1
        self.test_var = 0

        # Neptune run
        self.run = run

    def forward(self, x):
        return self.generator(x)
    
    def generator_loss(self, prediction_image, target_image, prediction_label, target_label, real_label):
        """
        Generator loss (a combination of): 
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels which is all 1s
            2 - L1 / Mean Absolute Error (weighted by lambda)
                Between generated image and target image
            3 - Spectral Loss (Spectral Angle)
                Between generated image and target image
            4 - LFM Loss (Feature Matching Loss)
                Between weights from all layers of the discriminator
        """
        # Adverserial loss
        BCE_loss = self.BCE(prediction_label[0], torch.ones_like(target_label))
        # LFM loss
        LFM_loss = torch.zeros((1,1,1,1)).to(c.DEVICE)
        LFM_weights = [1./16, 1./8, 1./4, 1./4, 1./2, 1.]
        for i, tensors in enumerate(zip(prediction_label[1], real_label[1])):
            LFM_loss += func.l1_loss(tensors[0], tensors[1]) * LFM_weights[i]
        # Other losses
        L1 = func.l1_loss(prediction_image, target_image)
        SPEC = spectral_angle_mapper(prediction_image, target_image)
        RASE = u.rase_error(prediction_image.add(1).mul(0.5), target_image.add(1).mul(0.5))
        SSIM = u.ssim3D(prediction_image.unsqueeze(1).add(1).mul(0.5), target_image.unsqueeze(1).add(1).mul(0.5)) # adding dimension so 3D works correctly

        return BCE_loss, L1, SPEC, LFM_loss, RASE, SSIM

    def discriminator_loss(self, prediction_label, target_label):
        """
        Discriminator loss: 
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels
                The target would be all 0s if the input of the discriminator is the generated image (generator)
                The target would be all 1s if the input of the discriminator is the target image (dataloader)
        """
        bce_loss = self.BCE(prediction_label, target_label) # index 0 since these are the output weights
        return bce_loss
    
    def configure_optimizers(self):
        """
        Using Adam optimizer for both generator and discriminator
        Both would have different initial learning rates
        Stochastic Gradient Descent with Warm Restarts is also added as learning scheduler (https://arxiv.org/abs/1608.03983)
        """
        # Optimizers
        generator_optimizer = o.Adam(self.generator.parameters(), lr=self.generator_lr, weight_decay=1e-5)
        discriminator_optimizer = o.Adam(self.discriminator.parameters(), lr=self.discriminator_lr, weight_decay=1e-5)
        # Learning Scheduler Generator
        gen_const_lr = o.lr_scheduler.ConstantLR(generator_optimizer, factor=1.0)
        gen_exp_lr = o.lr_scheduler.ExponentialLR(generator_optimizer, gamma=c.LR_GAMMA)
        generator_lr_scheduler = o.lr_scheduler.SequentialLR(generator_optimizer, [gen_const_lr, gen_exp_lr], [c.LR_START_DECAY])
        # Learning Scheduler Discriminator
        dis_const_lr = o.lr_scheduler.ConstantLR(discriminator_optimizer, factor=1.0)
        dis_exp_lr = o.lr_scheduler.ExponentialLR(discriminator_optimizer, gamma=c.LR_GAMMA)
        discriminator_lr_scheduler = o.lr_scheduler.SequentialLR(discriminator_optimizer, [dis_const_lr, dis_exp_lr], [c.LR_START_DECAY])

        return [generator_optimizer, discriminator_optimizer], [generator_lr_scheduler, discriminator_lr_scheduler]

    def training_step(self, batch, batch_idx):
        # Optimizers
        generator_optimizer, discriminator_optimizer = self.optimizers()
        generator_lr_scheduler, discriminator_lr_scheduler = self.lr_schedulers()
        
        image, target = batch
        image_i, image_j = (image, image) #torch.split(image, c.BATCH_SIZE)
        target_i, target_j = (target, target) #torch.split(target, c.BATCH_SIZE)
        # Should Disc and Gen be trained on different images?
        
        ######################################
        #  Discriminator Loss and Optimizer  #
        ######################################
        # Generator Feed-Forward
        generator_prediction = self.forward(image_i)
        # Discriminator Feed-Forward
        discriminator_prediction_real = self.discriminator(image_i, target_i)
        discriminator_prediction_fake = self.discriminator(image_i, generator_prediction)
        # Discriminator Loss
        discriminator_label_real = self.discriminator_loss(discriminator_prediction_real[0], 
                                                           torch.ones_like(discriminator_prediction_real[0]))
        discriminator_label_fake = self.discriminator_loss(discriminator_prediction_fake[0],
                                                           torch.zeros_like(discriminator_prediction_fake[0]))
        discriminator_loss = discriminator_label_real + discriminator_label_fake
        # Discriminator Optimizer
        discriminator_optimizer.zero_grad()
        discriminator_loss.backward()
        discriminator_optimizer.step()
        discriminator_lr_scheduler.step()
        
        ##################################
        #  Generator Loss and Optimizer  #
        ##################################
        #  Generator Feed-Forward
        generator_prediction = self.forward(image_j)
        # Discriminator Feed-Forward
        discriminator_prediction_fake = self.discriminator(image_j, generator_prediction)
        discriminator_prediction_real = self.discriminator(image_i, target_i)
        # Generator loss
        gen_loss_tuple = self.generator_loss(generator_prediction, target_j, discriminator_prediction_fake, 
                                             torch.ones_like(discriminator_prediction_fake[0]), 
                                             discriminator_prediction_real)
        gen_bce_loss, gen_l1_loss, gen_spec_loss, gen_lfm_loss, gen_rase_loss, gen_ssim = gen_loss_tuple
        generator_loss = gen_bce_loss * c.LAMBDA_ADV 
        generator_loss += gen_l1_loss * c.LAMBDA_L1
        generator_loss += gen_spec_loss * c.LAMBDA_SAM
        generator_loss += gen_lfm_loss.item() * c.LAMBDA_LFM
        generator_loss += gen_rase_loss * c.LAMBDA_RASE
        generator_loss += gen_ssim * c.LAMBDA_SSIM * -1
        # Generator Optimizer
        generator_optimizer.zero_grad()
        generator_loss.backward()
        generator_optimizer.step()
        generator_lr_scheduler.step()
        
        # Progressbar and Logging
        current_loss = {}
        current_loss["train/gen/loss"] = generator_loss.item()
        current_loss['train/gen/loss_1'] = gen_l1_loss.item()
        current_loss['train/gen/loss_adv'] = gen_bce_loss.item()
        current_loss['train/gen/loss_sam'] = gen_spec_loss.item()
        current_loss['train/gen/loss_lfm'] = gen_lfm_loss.item()
        current_loss['train/gen/loss_rase'] = gen_rase_loss.item()
        current_loss['train/gen/loss_ssim'] = gen_ssim.item()
        current_loss['train/gen/lr'] = generator_lr_scheduler.get_last_lr()[0]
        current_loss["train/dis/loss"] = discriminator_loss.item()
        current_loss['train/dis/loss_real'] = discriminator_label_real.item()
        current_loss['train/dis/loss_fake'] = discriminator_label_fake.item()
        current_loss['train/dis/lr'] = discriminator_lr_scheduler.get_last_lr()[0]
        self.log_dict(current_loss)

        return current_loss
    
    def log_dict(self, dic):
        # Neptune log
        if self.run != None:
            for key, value in dic.items():
                self.run[key].log(value=value, step=self.global_step)

    def validation_step(self, batch, batch_idx):
        image, target = batch
        
        # Generator Feed-Forward
        generator_prediction = self.forward(image)
        # Generator Metrics
        generator_psnr = peak_signal_noise_ratio(generator_prediction, target)
        generator_ssim = structural_similarity_index_measure(generator_prediction, target)
        discriminator_prediction_fake = self.discriminator(image, generator_prediction)
        generator_accuracy = accuracy(discriminator_prediction_fake[0], torch.ones_like(discriminator_prediction_fake[0], dtype=torch.int32), task='binary')
        generator_spectral_angle = spectral_angle_mapper(generator_prediction, target)
        generator_rase = u.rase_error(generator_prediction.add(1).mul(0.5), target.add(1).mul(0.5))
        generator_ssim3D = u.ssim3D(generator_prediction.unsqueeze(1).add(1).mul(0.5), target.unsqueeze(1).add(1).mul(0.5))
        # print(generator_rase.size(), generator_ssim3D.size(), generator_spectral_angle.size())
        
        # Discriminator Feed-Forward
        discriminator_prediction_real = self.discriminator(image, target)
        discriminator_prediction_fake = self.discriminator(image, generator_prediction)
        # Discriminator Metrics
        discriminator_accuracy = accuracy(discriminator_prediction_real[0], torch.ones_like(discriminator_prediction_real[0], dtype=torch.int32), task='binary') * 0.5 + \
                                accuracy(discriminator_prediction_fake[0], torch.zeros_like(discriminator_prediction_fake[0], dtype=torch.int32), task='binary') * 0.5

        # return everything that will be logged
        stats = [generator_psnr.cpu(), generator_ssim.cpu(), generator_accuracy.cpu(), discriminator_accuracy.cpu(), generator_rase.cpu(), generator_spectral_angle.cpu(), generator_ssim3D.cpu()]
        return stats, generator_prediction, target

    def on_validation_batch_end(self, outputs, batch, batch_idx):
        stats, generator_prediction, target = outputs

        # save stats for epoch end
        self.val_outputs = np.append(self.val_outputs, stats)
        self.val_outputs.shape = (-1, len(stats))

        # Example images
        if (batch_idx == 0 or c.LOG_ALL) and self.run != None and c.LOG_IMAGES == True:
            plot = u.create_plot_with_spectra(generator_prediction, target, epoch=self.current_epoch, step=self.global_step)
            # save example to array
            self.run[f"examples/example_array"].append(value=plot, step=self.global_step)
            # save example for comparison
            self.run[f"examples/example_epoch={self.current_epoch}_step={self.global_step}_idx={batch_idx}"].upload(plot)
            self.last_epoch_logged = self.current_epoch
            plt.close(plot)
            print("Uploaded example plot")

    def on_validation_epoch_end(self):
        # Calculate mean of stats
        metric_array = np.mean(self.val_outputs, axis=0)
        
        # Logging
        metrics = {'val/gen/psnr': metric_array[0], 'val/gen/ssim': metric_array[1], 
                   'val/gen/accuracy': metric_array[2], 'val/dis/accuracy': metric_array[3],
                   'val/gen/rase': metric_array[4], 'val/gen/sam': metric_array[5],
                   'val/gen/ssim3D': metric_array[6]}
        # log for Lightning monitoring
        self.log('rase', metrics['val/gen/rase'])
        # Log to neptune
        if self.global_step != 0: # don't log the values if nothing has been trained
            self.log_dict(metrics)

    def on_train_epoch_end(self):
        super().on_train_epoch_end()
        torch.cuda.empty_cache()

if __name__ == "__main__":
    pass